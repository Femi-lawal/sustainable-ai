{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7c69a9",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Project Architecture (Simple Explanation)\n",
    "\n",
    "Think of the project like a **factory assembly line**:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                     SUSTAINABLE AI PIPELINE                          ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                      ‚îÇ\n",
    "‚îÇ  [USER] ‚îÄ‚îÄ‚ñ∫ [GUI] ‚îÄ‚îÄ‚ñ∫ [NLP] ‚îÄ‚îÄ‚ñ∫ [ML] ‚îÄ‚îÄ‚ñ∫ [RESULTS]                  ‚îÇ\n",
    "‚îÇ                                                                      ‚îÇ\n",
    "‚îÇ  You type    Web      Text      Predict    Show energy              ‚îÇ\n",
    "‚îÇ  a prompt    form     analysis  energy     & suggestions            ‚îÇ\n",
    "‚îÇ                                                                      ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### The 4 Main Parts:\n",
    "\n",
    "| Part | Folder | What It Does |\n",
    "|------|--------|--------------|\n",
    "| **GUI** | `src/gui/` | Web interface where you type prompts |\n",
    "| **NLP** | `src/nlp/` | Analyzes text (counts tokens, measures complexity) |\n",
    "| **ML** | `src/ml/` | Predicts energy using machine learning |\n",
    "| **Utils** | `src/utils/` | Helpers (database, logging, config) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae8e47",
   "metadata": {},
   "source": [
    "## üìÅ Folder Structure Explained\n",
    "\n",
    "```\n",
    "Sustainable_AI_G3--main/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ src/                    # SOURCE CODE (the brain)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ gui/                # Web interface (Streamlit)\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py          # Main web app\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ layout.py       # UI components\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ nlp/                # Text analysis\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parser.py       # Tokenize prompts\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ complexity_score.py  # Calculate complexity\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ simplifier.py   # Make prompts simpler (enhanced!)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ prediction/         # Energy prediction\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ estimator.py    # Energy prediction model (R¬≤=0.976!)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ detection/          # Anomaly detection\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ detector.py     # Isolation Forest for outliers\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ optimization/       # Prompt optimization\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ recomender.py   # Energy-efficient recommendations\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ data/               # Data generation\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generate_training_data.py  # NEW! Creates 500 samples\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ training/           # Model training\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ improved_trainer.py  # NEW! Hyperparameter tuning\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ utils/              # Helpers\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ config.py       # Settings (updated paths!)\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ database.py     # Store logs\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ data/                   # DATA FILES\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Original prompts (raw_prompts.csv)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ processed/          # training_dataset.csv (500 samples!)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ synthetic/          # Old energy_dataset.csv (50 samples)\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ model/                  # SAVED ML MODELS\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ energy_predictor.pkl     # Gradient Boosting model ‚≠ê\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ feature_scaler.pkl       # StandardScaler\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ feature_names.pkl        # 12 feature names\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ notebooks/              # JUPYTER NOTEBOOKS (you are here!)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Project_Overview_Guide.ipynb  # This file!\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ traning_notebooks/  # Training & analysis notebooks\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ tests/                  # UNIT TESTS (256 tests!)\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ reports/                # OUTPUT REPORTS\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ figures/            # Saved visualizations\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ documentation/          # DOCS & DIAGRAMS\n",
    "    ‚îú‚îÄ‚îÄ architecture.md     # System diagrams\n",
    "    ‚îî‚îÄ‚îÄ user_manual.md      # User guide\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ee7de",
   "metadata": {},
   "source": [
    "## üîÑ How Everything Connects\n",
    "\n",
    "### Data Flow (Step by Step)\n",
    "\n",
    "```\n",
    "1. USER types: \"Explain quantum computing in detail\"\n",
    "       ‚Üì\n",
    "2. PARSER counts: 5 words, 34 chars, 7 tokens\n",
    "       ‚Üì\n",
    "3. COMPLEXITY SCORER calculates: 0.35 (medium)\n",
    "       ‚Üì\n",
    "4. ENERGY PREDICTOR predicts: 2.8 Joules\n",
    "       ‚Üì\n",
    "5. ANOMALY DETECTOR checks: Normal ‚úÖ\n",
    "       ‚Üì\n",
    "6. SIMPLIFIER suggests: \"Explain quantum computing\"\n",
    "       ‚Üì\n",
    "7. DISPLAY shows: Energy, Carbon footprint, Suggestions\n",
    "```\n",
    "\n",
    "### Module Connections\n",
    "\n",
    "| Module | Depends On | Used By |\n",
    "|--------|------------|--------|\n",
    "| `parser.py` | None | complexity_score, estimator, detector |\n",
    "| `complexity_score.py` | parser | estimator, recommender |\n",
    "| `estimator.py` | parser, complexity | app.py, recommender |\n",
    "| `detector.py` | parser | app.py |\n",
    "| `simplifier.py` | None | recommender |\n",
    "| `app.py` | All above | User (you!) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06c881",
   "metadata": {},
   "source": [
    "## ü§ñ Machine Learning Models\n",
    "\n",
    "### 1. Energy Predictor (Supervised Learning) - CALIBRATED MODEL ‚≠ê\n",
    "\n",
    "**What it does**: Predicts energy consumption from prompt features\n",
    "\n",
    "**Algorithm**: Gradient Boosting Regressor\n",
    "\n",
    "**Training Approach**: Hybrid (Synthetic + Real Measurements)\n",
    "- 2,000 synthetic samples (calibrated formula)\n",
    "- 100 real energy measurements\n",
    "- 500 augmented real samples\n",
    "\n",
    "**Input Features** (6 core features):\n",
    "| Feature | Description | Importance |\n",
    "|---------|-------------|------------|\n",
    "| token_count | Number of tokens | **Primary** ‚≠ê |\n",
    "| word_count | Number of words | High |\n",
    "| char_count | Character count | High |\n",
    "| complexity_score | Linguistic complexity | Medium |\n",
    "| avg_word_length | Average word length | Low |\n",
    "| avg_sentence_length | Avg words per sentence | Low |\n",
    "\n",
    "**Output**: Energy in Joules (or kWh for environmental calculations)\n",
    "\n",
    "**Performance (Professional Standards) ‚úÖ**: \n",
    "| Metric | Target | Achieved | Status |\n",
    "|--------|--------|----------|--------|\n",
    "| **R¬≤ Score** | > 0.80 | **0.9813** | ‚úÖ |\n",
    "| **MAPE** | < 25% | **6.8%** | ‚úÖ |\n",
    "| **Prediction Bias** | 0.90-1.10 | **0.9988** | ‚úÖ |\n",
    "| **Correlation** | > 0.85 | **0.9906** | ‚úÖ |\n",
    "| **Within 20%** | > 70% | **94.0%** | ‚úÖ |\n",
    "\n",
    "**Calibration Formula** (derived from real measurements):\n",
    "```\n",
    "Energy (J) = 9.27 + 0.331 √ó tokens\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Anomaly Detector (Unsupervised Learning)\n",
    "\n",
    "**What it does**: Flags unusually expensive prompts\n",
    "\n",
    "**Algorithm**: Isolation Forest\n",
    "\n",
    "**How it works**: Identifies prompts that are \"isolated\" (unusual) in feature space\n",
    "\n",
    "**Output**: Anomaly score (-1 = anomaly, +1 = normal)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Text Simplifier (NLP Optimization)\n",
    "\n",
    "**What it does**: Reduces prompt complexity while preserving meaning\n",
    "\n",
    "**Strategies**:\n",
    "| Strategy | Description | Typical Reduction |\n",
    "|----------|-------------|-------------------|\n",
    "| aggressive | All strategies combined | 30-50% |\n",
    "| verbose | Remove verbose phrases | 15-25% |\n",
    "| filler | Remove filler words | 5-15% |\n",
    "| core | Extract core question | 20-40% |\n",
    "| truncate | Keep essential sentences | 30-50% |\n",
    "\n",
    "**Energy Savings**: 8-43% depending on prompt verbosity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9593f7",
   "metadata": {},
   "source": [
    "## üöÄ How to Run the Project\n",
    "\n",
    "### Quick Start (3 Commands)\n",
    "\n",
    "```bash\n",
    "# 1. Activate virtual environment\n",
    "cd Sustainable_AI_G3--main\n",
    ".venv\\Scripts\\activate   # Windows\n",
    "source .venv/bin/activate  # Mac/Linux\n",
    "\n",
    "# 2. Run the web app\n",
    "streamlit run src/gui/app.py\n",
    "\n",
    "# 3. Open browser\n",
    "# Go to: http://localhost:8501\n",
    "```\n",
    "\n",
    "### Run Tests\n",
    "\n",
    "```bash\n",
    "# Run all 256 tests\n",
    "python -m pytest tests/ -v\n",
    "\n",
    "# Run specific test file\n",
    "python -m pytest tests/test_predictor.py -v\n",
    "```\n",
    "\n",
    "### Run Notebooks\n",
    "\n",
    "```bash\n",
    "# Launch Jupyter\n",
    "jupyter notebook\n",
    "\n",
    "# Open any notebook in notebooks/ folder\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e117cda",
   "metadata": {},
   "source": [
    "## üìì Notebook Guide\n",
    "\n",
    "### Training Notebooks (in `notebooks/traning_notebooks/`)\n",
    "\n",
    "| Notebook | Purpose | Run Order |\n",
    "|----------|---------|----------|\n",
    "| `DataFeatureEngineering.ipynb` | Extract features from prompts | 1st |\n",
    "| `_NLP_Prompt_Analysis.ipynb` | Analyze prompt complexity | 2nd |\n",
    "| `Energy Prediction ML.ipynb` | Train energy models | 3rd |\n",
    "| `masterbook.ipynb` | Complete pipeline demo | Anytime |\n",
    "| `GUI Sreamlit Integration.ipynb` | GUI documentation | Reference |\n",
    "\n",
    "### Recommended Learning Path\n",
    "\n",
    "1. **Start here** ‚Üí `masterbook.ipynb` (see the full pipeline)\n",
    "2. **Understand NLP** ‚Üí `_NLP_Prompt_Analysis.ipynb`\n",
    "3. **Learn ML** ‚Üí `Energy Prediction ML.ipynb`\n",
    "4. **Run the app** ‚Üí Follow GUI notebook instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f6e314",
   "metadata": {},
   "source": [
    "## üìä Data Files Explained\n",
    "\n",
    "### 1. Raw Prompts (`data/raw/raw_prompts.csv`)\n",
    "- **50 original prompts** with categories\n",
    "- Categories: simple, explanation, coding, question, creative, comparison, complex\n",
    "\n",
    "```\n",
    "prompt_id | prompt                                    | category\n",
    "----------|-------------------------------------------|------------\n",
    "P001      | What is the capital of France?           | simple\n",
    "P002      | Explain the theory of relativity...      | explanation\n",
    "P003      | Write a Python function to sort...       | coding\n",
    "```\n",
    "\n",
    "### 2. Training Dataset (`data/processed/training_dataset.csv`) ‚≠ê NEW\n",
    "- **500 samples** with all features and energy labels\n",
    "- Generated using `src/data/generate_training_data.py`\n",
    "- Proper correlations between features and energy\n",
    "\n",
    "```\n",
    "prompt_id | token_count | word_count | complexity_score | energy_joules\n",
    "----------|-------------|------------|------------------|---------------\n",
    "P001      | 7           | 6          | 2.28             | 0.2834\n",
    "P002      | 9           | 8          | 2.85             | 0.4521\n",
    "...       | ...         | ...        | ...              | ...\n",
    "P500      | 15          | 12         | 4.17             | 0.8234\n",
    "```\n",
    "\n",
    "### 3. Features (`data/processed/features.csv`)\n",
    "- **12 extracted NLP features** per prompt (original 50)\n",
    "\n",
    "### 4. Energy Labels (`data/synthetic/energy_dataset.csv`)\n",
    "- **Original synthetic data** (50 samples) - for reference only\n",
    "- New training uses `training_dataset.csv` instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cee330",
   "metadata": {},
   "source": [
    "## üéØ Key Results Summary\n",
    "\n",
    "### Model Performance (December 2025 - Professional Standards Met!)\n",
    "\n",
    "| Metric | Target | Achieved | Status |\n",
    "|--------|--------|----------|--------|\n",
    "| **R¬≤ Score** | > 0.80 | **0.9813** | ‚úÖ |\n",
    "| **MAPE** | < 25% | **6.8%** | ‚úÖ |\n",
    "| **Prediction Bias** | 0.90-1.10 | **0.9988** | ‚úÖ |\n",
    "| **Correlation** | > 0.85 | **0.9906** | ‚úÖ |\n",
    "| **Within 20%** | > 70% | **94.0%** | ‚úÖ |\n",
    "\n",
    "*Note: Model is calibrated against 100 real energy measurements!*\n",
    "\n",
    "### Training Data\n",
    "\n",
    "| Dataset | Samples | Purpose |\n",
    "|---------|---------|---------|\n",
    "| Synthetic (calibrated) | 2,000 | Base training |\n",
    "| Real measurements | 100 | Ground truth |\n",
    "| Augmented real | 500 | Enhance accuracy |\n",
    "| **Total** | **2,600** | Production model |\n",
    "\n",
    "### Feature Importance (What Matters Most)\n",
    "\n",
    "1. **Token count** - More tokens = more energy ‚≠ê\n",
    "2. **Word count** - Longer prompts = more processing\n",
    "3. **Char count** - Character-level complexity\n",
    "4. **Complexity score** - Linguistic complexity\n",
    "\n",
    "### Energy Calibration Formula\n",
    "```\n",
    "Energy (Joules) = 9.27 + 0.331 √ó token_count\n",
    "```\n",
    "(R¬≤ = 0.871 on real measurements)\n",
    "\n",
    "### Energy Savings from Optimization\n",
    "\n",
    "| Original Prompt | Simplified | Energy Reduction |\n",
    "|-----------------|------------|------------------|\n",
    "| \"Due to the fact that I need assistance...\" | \"Because I need help...\" | **35.1%** |\n",
    "| \"I was wondering if you could perhaps maybe...\" | \"Please tell me...\" | **42.6%** |\n",
    "| \"In order to understand...\" | \"To understand...\" | **13.4%** |\n",
    "| \"Basically, what is AI?\" | \"What is AI?\" | **8.0%** |\n",
    "\n",
    "### Test Coverage\n",
    "\n",
    "- **283 tests** across all modules\n",
    "- **100% pass rate** ‚úÖ\n",
    "- All modules covered: config, database, detector, estimator, parser, simplifier, integration, validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d54a2",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "| Problem | Solution |\n",
    "|---------|----------|\n",
    "| `ModuleNotFoundError` | Activate venv: `.venv\\Scripts\\activate` |\n",
    "| `FileNotFoundError` for data | Run from project root folder |\n",
    "| Streamlit won't start | `pip install streamlit` |\n",
    "| Tests fail | `pip install -r requirements.txt` |\n",
    "\n",
    "### Environment Check\n",
    "\n",
    "```bash\n",
    "# Verify Python version (should be 3.9+)\n",
    "python --version\n",
    "\n",
    "# Verify packages\n",
    "pip list | grep streamlit\n",
    "pip list | grep scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69335397",
   "metadata": {},
   "source": [
    "## üìö Documentation Links\n",
    "\n",
    "| Document | Location | Description |\n",
    "|----------|----------|-------------|\n",
    "| README | `README.md` | Project overview |\n",
    "| Architecture | `documentation/architecture.md` | System diagrams |\n",
    "| User Manual | `documentation/user_manual.md` | Usage guide |\n",
    "| Requirements | `requirements.txt` | Python packages |\n",
    "\n",
    "---\n",
    "\n",
    "## üë• Team Members\n",
    "\n",
    "| Name | Student ID |\n",
    "|------|------------|\n",
    "| Jarius Bedward | #8841640 |\n",
    "| Mostafa Allahmoradi | - |\n",
    "| Oluwafemi Lawal | - |\n",
    "| Jatinder Pal Singh | - |\n",
    "\n",
    "---\n",
    "\n",
    "*CSCN8010 Final Project - Sustainable AI Energy Monitor*\n",
    "\n",
    "**Last Updated**: December 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac160d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå± Sustainable AI - Environment Check\n",
      "==================================================\n",
      "\n",
      "üìÅ Project root: c:\\Users\\femil\\Documents\\PersonalProjects\\CNSTG\\AIML\\Sustainable_AI_G3--main\n",
      "üêç Python: 3.13.7\n",
      "\n",
      "üìã Directory Check:\n",
      "  ‚úÖ src/ - Source code\n",
      "  ‚úÖ data/ - Data files\n",
      "  ‚úÖ model/ - ML models\n",
      "  ‚úÖ tests/ - Unit tests\n",
      "  ‚úÖ notebooks/ - Notebooks\n",
      "\n",
      "üì¶ Package Check:\n",
      "  ‚úÖ sklearn\n",
      "  ‚úÖ pandas\n",
      "  ‚úÖ numpy\n",
      "  ‚úÖ matplotlib\n",
      "  ‚úÖ streamlit\n",
      "\n",
      "==================================================\n",
      "‚úÖ Environment check complete!\n"
     ]
    }
   ],
   "source": [
    "# Quick verification that everything works\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up project path\n",
    "project_root = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"üå± Sustainable AI - Environment Check\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nüìÅ Project root: {project_root}\")\n",
    "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check key directories exist\n",
    "checks = [\n",
    "    ('src/', 'Source code'),\n",
    "    ('data/', 'Data files'),\n",
    "    ('model/', 'ML models'),\n",
    "    ('tests/', 'Unit tests'),\n",
    "    ('notebooks/', 'Notebooks'),\n",
    "]\n",
    "\n",
    "print(\"\\nüìã Directory Check:\")\n",
    "for folder, desc in checks:\n",
    "    exists = (project_root / folder).exists()\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"  {status} {folder} - {desc}\")\n",
    "\n",
    "# Check key packages\n",
    "print(\"\\nüì¶ Package Check:\")\n",
    "packages = ['sklearn', 'pandas', 'numpy', 'matplotlib', 'streamlit']\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        print(f\"  ‚úÖ {pkg}\")\n",
    "    except ImportError:\n",
    "        print(f\"  ‚ùå {pkg} - run: pip install {pkg}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"‚úÖ Environment check complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
