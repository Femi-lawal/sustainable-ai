{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7c69a9",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Project Architecture (Simple Explanation)\n",
    "\n",
    "Think of the project like a **factory assembly line**:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     SUSTAINABLE AI PIPELINE                          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                      â”‚\n",
    "â”‚  [USER] â”€â”€â–º [GUI] â”€â”€â–º [NLP] â”€â”€â–º [ML] â”€â”€â–º [RESULTS]                  â”‚\n",
    "â”‚                                                                      â”‚\n",
    "â”‚  You type    Web      Text      Predict    Show energy              â”‚\n",
    "â”‚  a prompt    form     analysis  energy     & suggestions            â”‚\n",
    "â”‚                                                                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### The 4 Main Parts:\n",
    "\n",
    "| Part | Folder | What It Does |\n",
    "|------|--------|--------------|\n",
    "| **GUI** | `src/gui/` | Web interface where you type prompts |\n",
    "| **NLP** | `src/nlp/` | Analyzes text (counts tokens, measures complexity) |\n",
    "| **Prediction** | `src/prediction/` | Predicts energy using Random Forest |\n",
    "| **Utils** | `src/utils/` | Helpers (database, logging, config) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae8e47",
   "metadata": {},
   "source": [
    "## ğŸ“ Folder Structure Explained\n",
    "\n",
    "```\n",
    "Sustainable_AI_G3--main/\n",
    "â”‚\n",
    "â”œâ”€â”€ src/                    # SOURCE CODE (the brain)\n",
    "â”‚   â”œâ”€â”€ gui/                # Web interface (Streamlit)\n",
    "â”‚   â”‚   â”œâ”€â”€ app.py          # Main web app\n",
    "â”‚   â”‚   â””â”€â”€ layout.py       # UI components\n",
    "â”‚   â”œâ”€â”€ nlp/                # Text analysis\n",
    "â”‚   â”‚   â”œâ”€â”€ prompt_parser.py    # Tokenize prompts\n",
    "â”‚   â”‚   â”œâ”€â”€ complexity_score.py # Calculate complexity\n",
    "â”‚   â”‚   â””â”€â”€ text_simplifier.py  # Make prompts simpler\n",
    "â”‚   â”œâ”€â”€ prediction/         # Energy prediction\n",
    "â”‚   â”‚   â””â”€â”€ estimator.py    # Energy prediction model (RÂ²=0.9809!)\n",
    "â”‚   â”œâ”€â”€ anomaly/            # Anomaly detection\n",
    "â”‚   â”‚   â””â”€â”€ detector.py     # Isolation Forest for outliers\n",
    "â”‚   â”œâ”€â”€ optimization/       # Prompt optimization\n",
    "â”‚   â”‚   â””â”€â”€ recommender.py  # Energy-efficient recommendations\n",
    "â”‚   â”œâ”€â”€ data/               # Data generation\n",
    "â”‚   â”‚   â””â”€â”€ generate_training_data.py  # Creates training samples\n",
    "â”‚   â”œâ”€â”€ training/           # Model training\n",
    "â”‚   â”‚   â””â”€â”€ improved_trainer.py  # Hyperparameter tuning\n",
    "â”‚   â””â”€â”€ utils/              # Helpers\n",
    "â”‚       â”œâ”€â”€ config.py       # Settings (updated paths!)\n",
    "â”‚       â””â”€â”€ database.py     # Store logs\n",
    "â”‚\n",
    "â”œâ”€â”€ data/                   # DATA FILES\n",
    "â”‚   â”œâ”€â”€ raw/                # Original prompts (raw_prompts.csv)\n",
    "â”‚   â”œâ”€â”€ processed/          # training_dataset.csv \n",
    "â”‚   â”œâ”€â”€ synthetic/          # energy_dataset.csv\n",
    "â”‚   â””â”€â”€ validation/         # real_measurements.csv (100 samples)\n",
    "â”‚\n",
    "â”œâ”€â”€ model/                  # SAVED ML MODELS\n",
    "â”‚   â”œâ”€â”€ calibrated_energy_model.joblib  # Random Forest model â­\n",
    "â”‚   â”œâ”€â”€ calibrated_scaler.joblib        # StandardScaler (5 features)\n",
    "â”‚   â””â”€â”€ calibration_info.joblib         # Model metadata\n",
    "â”‚\n",
    "â”œâ”€â”€ notebooks/              # JUPYTER NOTEBOOKS (you are here!)\n",
    "â”‚   â”œâ”€â”€ Project_Overview_Guide.ipynb    # This file!\n",
    "â”‚   â””â”€â”€ traning_notebooks/              # Training & analysis notebooks\n",
    "â”‚       â”œâ”€â”€ Assignment_Model_Training.ipynb  # Assignment-compliant (LR, RF, NN)\n",
    "â”‚       â””â”€â”€ masterbook.ipynb                 # Complete pipeline demo\n",
    "â”‚\n",
    "â”œâ”€â”€ tests/                  # UNIT TESTS (283 tests!)\n",
    "â”‚\n",
    "â”œâ”€â”€ reports/                # OUTPUT REPORTS\n",
    "â”‚   â””â”€â”€ figures/            # Saved visualizations\n",
    "â”‚\n",
    "â””â”€â”€ documentation/          # DOCS & DIAGRAMS\n",
    "    â”œâ”€â”€ architecture.md     # System diagrams\n",
    "    â””â”€â”€ user_manual.md      # User guide\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ee7de",
   "metadata": {},
   "source": [
    "## ğŸ”„ How Everything Connects\n",
    "\n",
    "### Data Flow (Step by Step)\n",
    "\n",
    "```\n",
    "1. USER types: \"Explain quantum computing in detail\"\n",
    "       â†“\n",
    "2. PARSER counts: 5 words, 34 chars, 7 tokens\n",
    "       â†“\n",
    "3. COMPLEXITY SCORER calculates: 0.35 (medium)\n",
    "       â†“\n",
    "4. ENERGY PREDICTOR predicts: 2.8 Joules\n",
    "       â†“\n",
    "5. ANOMALY DETECTOR checks: Normal âœ…\n",
    "       â†“\n",
    "6. SIMPLIFIER suggests: \"Explain quantum computing\"\n",
    "       â†“\n",
    "7. DISPLAY shows: Energy, Carbon footprint, Suggestions\n",
    "```\n",
    "\n",
    "### Module Connections\n",
    "\n",
    "| Module | Depends On | Used By |\n",
    "|--------|------------|--------|\n",
    "| `parser.py` | None | complexity_score, estimator, detector |\n",
    "| `complexity_score.py` | parser | estimator, recommender |\n",
    "| `estimator.py` | parser, complexity | app.py, recommender |\n",
    "| `detector.py` | parser | app.py |\n",
    "| `simplifier.py` | None | recommender |\n",
    "| `app.py` | All above | User (you!) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06c881",
   "metadata": {},
   "source": [
    "## ğŸ¤– Machine Learning Models\n",
    "\n",
    "### 1. Energy Predictor (Supervised Learning) - CALIBRATED MODEL â­\n",
    "\n",
    "**What it does**: Predicts energy consumption from prompt features\n",
    "\n",
    "**Algorithm**: Random Forest Regressor (assignment-compliant)\n",
    "\n",
    "**Assignment Models Compared**:\n",
    "| Model | Test RÂ² | Test RMSE | Notes |\n",
    "|-------|---------|-----------|-------|\n",
    "| Linear Regression | 0.8696 | 8.58 J | Baseline |\n",
    "| **Random Forest** â­ | **0.9809** | **3.28 J** | **Selected** |\n",
    "| Neural Network (MLP) | ~0.95 | ~4.5 J | Deep learning option |\n",
    "\n",
    "**Training Data**: Hybrid (Synthetic + Real Measurements)\n",
    "- 2,000 synthetic samples (calibrated formula)\n",
    "- 100 real energy measurements (CodeCarbon)\n",
    "- 500 augmented real samples\n",
    "\n",
    "**Input Features** (5 core features):\n",
    "| Feature | Description | Importance |\n",
    "|---------|-------------|------------|\n",
    "| avg_sentence_length | Avg words per sentence | **26.4%** â­ |\n",
    "| token_count | Number of tokens | **23.8%** |\n",
    "| word_count | Number of words | **22.8%** |\n",
    "| char_count | Character count | **22.1%** |\n",
    "| avg_word_length | Average word length | 4.8% |\n",
    "\n",
    "**Note**: `complexity_score` was removed (constant 0.5 in real data)\n",
    "\n",
    "**Output**: Energy in Joules (or kWh for environmental calculations)\n",
    "\n",
    "**Performance (Professional Standards) âœ…**: \n",
    "| Metric | Target | Achieved | Status |\n",
    "|--------|--------|----------|--------|\n",
    "| **RÂ² Score** | > 0.80 | **0.9809** | âœ… |\n",
    "| **RMSE** | - | **3.28 J** | âœ… |\n",
    "| **MAE** | - | **2.46 J** | âœ… |\n",
    "| **Correlation** | > 0.85 | **0.93** | âœ… |\n",
    "| **Within 20%** | > 70% | **94.0%** | âœ… |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Anomaly Detector (Unsupervised Learning)\n",
    "\n",
    "**What it does**: Flags unusually expensive prompts\n",
    "\n",
    "**Algorithm**: Isolation Forest\n",
    "\n",
    "**How it works**: Identifies prompts that are \"isolated\" (unusual) in feature space\n",
    "\n",
    "**Output**: Anomaly score (-1 = anomaly, +1 = normal)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Text Simplifier (NLP Optimization)\n",
    "\n",
    "**What it does**: Reduces prompt complexity while preserving meaning\n",
    "\n",
    "**Strategies**:\n",
    "| Strategy | Description | Typical Reduction |\n",
    "|----------|-------------|-------------------|\n",
    "| aggressive | All strategies combined | 30-50% |\n",
    "| verbose | Remove verbose phrases | 15-25% |\n",
    "| filler | Remove filler words | 5-15% |\n",
    "| core | Extract core question | 20-40% |\n",
    "| truncate | Keep essential sentences | 30-50% |\n",
    "\n",
    "**Energy Savings**: 8-43% depending on prompt verbosity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9593f7",
   "metadata": {},
   "source": [
    "## ğŸš€ How to Run the Project\n",
    "\n",
    "### Quick Start (3 Commands)\n",
    "\n",
    "```bash\n",
    "# 1. Activate virtual environment\n",
    "cd Sustainable_AI_G3--main\n",
    ".venv\\Scripts\\activate   # Windows\n",
    "source .venv/bin/activate  # Mac/Linux\n",
    "\n",
    "# 2. Run the web app\n",
    "streamlit run src/gui/app.py\n",
    "\n",
    "# 3. Open browser\n",
    "# Go to: http://localhost:8501\n",
    "```\n",
    "\n",
    "### Run Tests\n",
    "\n",
    "```bash\n",
    "# Run all 256 tests\n",
    "python -m pytest tests/ -v\n",
    "\n",
    "# Run specific test file\n",
    "python -m pytest tests/test_predictor.py -v\n",
    "```\n",
    "\n",
    "### Run Notebooks\n",
    "\n",
    "```bash\n",
    "# Launch Jupyter\n",
    "jupyter notebook\n",
    "\n",
    "# Open any notebook in notebooks/ folder\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e117cda",
   "metadata": {},
   "source": [
    "## ğŸ““ Notebook Guide\n",
    "\n",
    "### Training Notebooks (in `notebooks/traning_notebooks/`)\n",
    "\n",
    "| Notebook | Purpose | Run Order |\n",
    "|----------|---------|----------|\n",
    "| `Assignment_Model_Training.ipynb` | **Authoritative** - Train RF model (RÂ²=0.9809) | 1st |\n",
    "| `_NLP_Prompt_Analysis.ipynb` | Analyze prompt complexity | 2nd |\n",
    "| `masterbook.ipynb` | Complete pipeline demo | Anytime |\n",
    "| `GUI Sreamlit Integration.ipynb` | GUI documentation | Reference |\n",
    "\n",
    "### Recommended Learning Path\n",
    "\n",
    "1. **Start here** â†’ `masterbook.ipynb` (see the full pipeline)\n",
    "2. **Understand NLP** â†’ `_NLP_Prompt_Analysis.ipynb`\n",
    "3. **Train ML Model** â†’ `Assignment_Model_Training.ipynb`\n",
    "4. **Run the app** â†’ Follow GUI notebook instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f6e314",
   "metadata": {},
   "source": [
    "## ğŸ“Š Data Files Explained\n",
    "\n",
    "### 1. Raw Prompts (`data/raw/raw_prompts.csv`)\n",
    "- **50 original prompts** with categories\n",
    "- Categories: simple, explanation, coding, question, creative, comparison, complex\n",
    "\n",
    "```\n",
    "prompt_id | prompt                                    | category\n",
    "----------|-------------------------------------------|------------\n",
    "P001      | What is the capital of France?           | simple\n",
    "P002      | Explain the theory of relativity...      | explanation\n",
    "P003      | Write a Python function to sort...       | coding\n",
    "```\n",
    "\n",
    "### 2. Training Dataset (`data/processed/training_dataset.csv`) â­ NEW\n",
    "- **500 samples** with all features and energy labels\n",
    "- Generated using `src/data/generate_training_data.py`\n",
    "- Proper correlations between features and energy\n",
    "\n",
    "```\n",
    "prompt_id | token_count | word_count | complexity_score | energy_joules\n",
    "----------|-------------|------------|------------------|---------------\n",
    "P001      | 7           | 6          | 2.28             | 0.2834\n",
    "P002      | 9           | 8          | 2.85             | 0.4521\n",
    "...       | ...         | ...        | ...              | ...\n",
    "P500      | 15          | 12         | 4.17             | 0.8234\n",
    "```\n",
    "\n",
    "### 3. Features (`data/processed/features.csv`)\n",
    "- **12 extracted NLP features** per prompt (original 50)\n",
    "\n",
    "### 4. Energy Labels (`data/synthetic/energy_dataset.csv`)\n",
    "- **Original synthetic data** (50 samples) - for reference only\n",
    "- New training uses `training_dataset.csv` instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cee330",
   "metadata": {},
   "source": [
    "## ğŸ¯ Key Results Summary\n",
    "\n",
    "### Model Performance (December 2025 - Random Forest)\n",
    "\n",
    "| Metric | Target | Achieved | Status |\n",
    "|--------|--------|----------|--------|\n",
    "| **RÂ² Score** | > 0.80 | **0.9809** | âœ… |\n",
    "| **RMSE** | - | **3.28 J** | âœ… |\n",
    "| **MAE** | - | **2.46 J** | âœ… |\n",
    "| **Correlation** | > 0.85 | **0.93** | âœ… |\n",
    "| **Within 20%** | > 70% | **94.0%** | âœ… |\n",
    "\n",
    "*Note: Model is calibrated against 100 real energy measurements!*\n",
    "\n",
    "### Training Data\n",
    "\n",
    "| Dataset | Samples | Purpose |\n",
    "|---------|---------|---------|\n",
    "| Synthetic (calibrated) | 2,000 | Base training |\n",
    "| Real measurements | 100 | Ground truth |\n",
    "| Augmented real | 500 | Enhance accuracy |\n",
    "| **Total** | **2,600** | Production model |\n",
    "\n",
    "### Feature Importance (What Matters Most)\n",
    "\n",
    "1. **Token count** - More tokens = more energy â­\n",
    "2. **Word count** - Longer prompts = more processing\n",
    "3. **Char count** - Character-level complexity\n",
    "4. **Avg word length** - Word complexity\n",
    "5. **Avg sentence length** - Sentence structure\n",
    "\n",
    "> **Note**: `complexity_score` was removed from production features (constant in real measurements).\n",
    "\n",
    "### Energy Calibration Formula\n",
    "```\n",
    "Energy (Joules) = 9.27 + 0.331 Ã— token_count\n",
    "```\n",
    "(RÂ² = 0.871 on real measurements)\n",
    "\n",
    "### Energy Savings from Optimization\n",
    "\n",
    "| Original Prompt | Simplified | Energy Reduction |\n",
    "|-----------------|------------|------------------|\n",
    "| \"Due to the fact that I need assistance...\" | \"Because I need help...\" | **35.1%** |\n",
    "| \"I was wondering if you could perhaps maybe...\" | \"Please tell me...\" | **42.6%** |\n",
    "| \"In order to understand...\" | \"To understand...\" | **13.4%** |\n",
    "| \"Basically, what is AI?\" | \"What is AI?\" | **8.0%** |\n",
    "\n",
    "### Test Coverage\n",
    "\n",
    "- **283 tests** across all modules\n",
    "- **100% pass rate** âœ…\n",
    "- All modules covered: config, database, detector, estimator, parser, simplifier, integration, validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d54a2",
   "metadata": {},
   "source": [
    "## ğŸ”§ Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "| Problem | Solution |\n",
    "|---------|----------|\n",
    "| `ModuleNotFoundError` | Activate venv: `.venv\\Scripts\\activate` |\n",
    "| `FileNotFoundError` for data | Run from project root folder |\n",
    "| Streamlit won't start | `pip install streamlit` |\n",
    "| Tests fail | `pip install -r requirements.txt` |\n",
    "\n",
    "### Environment Check\n",
    "\n",
    "```bash\n",
    "# Verify Python version (should be 3.9+)\n",
    "python --version\n",
    "\n",
    "# Verify packages\n",
    "pip list | grep streamlit\n",
    "pip list | grep scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69335397",
   "metadata": {},
   "source": [
    "## ğŸ“š Documentation Links\n",
    "\n",
    "| Document | Location | Description |\n",
    "|----------|----------|-------------|\n",
    "| README | `README.md` | Project overview |\n",
    "| Architecture | `documentation/architecture.md` | System diagrams |\n",
    "| User Manual | `documentation/user_manual.md` | Usage guide |\n",
    "| Requirements | `requirements.txt` | Python packages |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‘¥ Team Members\n",
    "\n",
    "| Name | Student ID |\n",
    "|------|------------|\n",
    "| Jarius Bedward | #8841640 |\n",
    "| Mostafa Allahmoradi | - |\n",
    "| Oluwafemi Lawal | - |\n",
    "| Jatinder Pal Singh | - |\n",
    "\n",
    "---\n",
    "\n",
    "*CSCN8010 Final Project - Sustainable AI Energy Monitor*\n",
    "\n",
    "**Last Updated**: December 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac160d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ± Sustainable AI - Environment Check\n",
      "==================================================\n",
      "\n",
      "ğŸ“ Project root: c:\\Users\\femil\\Documents\\PersonalProjects\\CNSTG\\AIML\\Sustainable_AI_G3--main\n",
      "ğŸ Python: 3.13.7\n",
      "\n",
      "ğŸ“‹ Directory Check:\n",
      "  âœ… src/ - Source code\n",
      "  âœ… data/ - Data files\n",
      "  âœ… model/ - ML models\n",
      "  âœ… tests/ - Unit tests\n",
      "  âœ… notebooks/ - Notebooks\n",
      "\n",
      "ğŸ“¦ Package Check:\n",
      "  âœ… sklearn\n",
      "  âœ… pandas\n",
      "  âœ… numpy\n",
      "  âœ… matplotlib\n",
      "  âœ… sklearn\n",
      "  âœ… pandas\n",
      "  âœ… numpy\n",
      "  âœ… matplotlib\n",
      "  âœ… streamlit\n",
      "\n",
      "==================================================\n",
      "âœ… Environment check complete!\n",
      "  âœ… streamlit\n",
      "\n",
      "==================================================\n",
      "âœ… Environment check complete!\n"
     ]
    }
   ],
   "source": [
    "# Quick verification that everything works\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up project path\n",
    "project_root = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"ğŸŒ± Sustainable AI - Environment Check\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nğŸ“ Project root: {project_root}\")\n",
    "print(f\"ğŸ Python: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check key directories exist\n",
    "checks = [\n",
    "    ('src/', 'Source code'),\n",
    "    ('data/', 'Data files'),\n",
    "    ('model/', 'ML models'),\n",
    "    ('tests/', 'Unit tests'),\n",
    "    ('notebooks/', 'Notebooks'),\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“‹ Directory Check:\")\n",
    "for folder, desc in checks:\n",
    "    exists = (project_root / folder).exists()\n",
    "    status = \"âœ…\" if exists else \"âŒ\"\n",
    "    print(f\"  {status} {folder} - {desc}\")\n",
    "\n",
    "# Check key packages\n",
    "print(\"\\nğŸ“¦ Package Check:\")\n",
    "packages = ['sklearn', 'pandas', 'numpy', 'matplotlib', 'streamlit']\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        print(f\"  âœ… {pkg}\")\n",
    "    except ImportError:\n",
    "        print(f\"  âŒ {pkg} - run: pip install {pkg}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"âœ… Environment check complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
